2020-10-28 18:45:08,992 - orignal model size (MB): 0.828236
2020-10-28 18:45:08,994 - # non-zero params before decomp: 185762
2020-10-28 18:45:09,287 - apply [tucker] DECOMP with rank: 2
2020-10-28 18:45:09,293 - decomp-ed model size (MB): 0.14583
2020-10-28 18:45:09,294 - # non-zero params after decomp: 8436
2020-10-28 18:45:09,299 - ===> loading train and dev dataset
2020-10-28 18:45:09,303 - ### Model summary below###
 AttenResNet4(
  (pre): Sequential(
    (0): Sequential(
      (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
  (down1): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att1): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(4, 8), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip1): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down2): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att2): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(8, 16), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip2): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down3): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att3): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(16, 32), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip3): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down4): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att4): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(32, 64), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip4): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down5): MaxPool2d(kernel_size=3, stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (att5): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(64, 128), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
  (up5): UpsamplingBilinear2d(size=(137, 851), mode=bilinear)
  (att6): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up4): UpsamplingBilinear2d(size=(201, 979), mode=bilinear)
  (att7): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up3): UpsamplingBilinear2d(size=(233, 1043), mode=bilinear)
  (att8): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up2): UpsamplingBilinear2d(size=(249, 1075), mode=bilinear)
  (att9): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up1): UpsamplingBilinear2d(size=(257, 1091), mode=bilinear)
  (conv1): Sequential(
    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): Sequential(
      (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): ReLU(inplace=True)
    (5): Sequential(
      (0): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (soft): Sigmoid()
  (cnn1): Sequential(
    (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re1): ReLU(inplace=True)
  (cnn2): Sequential(
    (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re2): ReLU(inplace=True)
  (cnn3): Sequential(
    (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp1): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn4): Sequential(
    (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re3): ReLU(inplace=True)
  (cnn5): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re4): ReLU(inplace=True)
  (cnn6): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn7): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re5): ReLU(inplace=True)
  (cnn8): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re6): ReLU(inplace=True)
  (cnn9): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn10): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re12): ReLU(inplace=True)
  (cnn11): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re13): ReLU(inplace=True)
  (cnn12): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn13): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re14): ReLU(inplace=True)
  (cnn14): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re15): ReLU(inplace=True)
  (cnn15): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn16): Sequential(
    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)
    (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (ln1): Sequential(
    (0): Linear(in_features=768, out_features=2, bias=False)
    (1): Linear(in_features=2, out_features=32, bias=True)
  )
  (bn7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re7): ReLU(inplace=True)
  (ln2): Sequential(
    (0): Linear(in_features=32, out_features=2, bias=False)
    (1): Linear(in_features=2, out_features=32, bias=True)
  )
  (bn8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re8): ReLU(inplace=True)
  (ln3): Sequential(
    (0): Linear(in_features=32, out_features=2, bias=False)
    (1): Linear(in_features=2, out_features=32, bias=True)
  )
  (bn9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re9): ReLU(inplace=True)
  (ln4): Sequential(
    (0): Linear(in_features=32, out_features=2, bias=False)
    (1): Linear(in_features=2, out_features=32, bias=True)
  )
  (bn10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re10): ReLU(inplace=True)
  (ln5): Sequential(
    (0): Linear(in_features=32, out_features=2, bias=False)
    (1): Linear(in_features=2, out_features=32, bias=True)
  )
  (bn11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re11): ReLU(inplace=True)
  (ln6): Sequential(
    (0): Linear(in_features=32, out_features=1, bias=False)
    (1): Linear(in_features=1, out_features=1, bias=True)
  )
  (sigmoid): Sigmoid()
)

2020-10-28 18:45:09,304 - ===> Model total parameter: 8436

2020-10-28 18:45:09,776 - Train Epoch: 1 [0/3014 (0%)]	Loss: 0.206563
2020-10-28 18:45:22,417 - Train Epoch: 1 [200/3014 (7%)]	Loss: 0.231830
2020-10-28 18:45:35,103 - Train Epoch: 1 [400/3014 (13%)]	Loss: 0.054055
2020-10-28 18:45:47,861 - Train Epoch: 1 [600/3014 (20%)]	Loss: 1.354081
2020-10-28 18:46:00,631 - Train Epoch: 1 [800/3014 (27%)]	Loss: 0.050416
2020-10-28 18:46:13,406 - Train Epoch: 1 [1000/3014 (33%)]	Loss: 0.647970
2020-10-28 18:46:26,187 - Train Epoch: 1 [1200/3014 (40%)]	Loss: 0.299788
2020-10-28 18:46:38,979 - Train Epoch: 1 [1400/3014 (46%)]	Loss: 0.131711
2020-10-28 18:46:51,785 - Train Epoch: 1 [1600/3014 (53%)]	Loss: 1.036902
2020-10-28 18:47:04,647 - Train Epoch: 1 [1800/3014 (60%)]	Loss: 0.186757
2020-10-28 18:47:17,515 - Train Epoch: 1 [2000/3014 (66%)]	Loss: 0.342216
2020-10-28 18:47:30,380 - Train Epoch: 1 [2200/3014 (73%)]	Loss: 0.036376
2020-10-28 18:47:43,251 - Train Epoch: 1 [2400/3014 (80%)]	Loss: 0.225778
2020-10-28 18:47:56,127 - Train Epoch: 1 [2600/3014 (86%)]	Loss: 0.256956
2020-10-28 18:48:09,017 - Train Epoch: 1 [2800/3014 (93%)]	Loss: 0.126631
2020-10-28 18:48:21,900 - Train Epoch: 1 [3000/3014 (99%)]	Loss: 0.209535
2020-10-28 18:48:22,584 - Starting Validation
2020-10-28 18:48:39,268 - ===> Validation set: Average loss: 0.4813	EER: 13.5439

2020-10-28 18:48:39,296 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank2-tucker-model_best.pth

2020-10-28 18:48:39,296 - #### End epoch 1/30, elapsed time: 209.99193449807353
2020-10-28 18:48:39,554 - Train Epoch: 2 [0/3014 (0%)]	Loss: 0.029414
2020-10-28 18:48:52,444 - Train Epoch: 2 [200/3014 (7%)]	Loss: 1.732054
2020-10-28 18:49:05,338 - Train Epoch: 2 [400/3014 (13%)]	Loss: 0.077937
2020-10-28 18:49:18,225 - Train Epoch: 2 [600/3014 (20%)]	Loss: 0.324156
2020-10-28 18:49:31,117 - Train Epoch: 2 [800/3014 (27%)]	Loss: 0.096370
2020-10-28 18:49:44,014 - Train Epoch: 2 [1000/3014 (33%)]	Loss: 0.076424
2020-10-28 18:49:56,911 - Train Epoch: 2 [1200/3014 (40%)]	Loss: 0.150216
2020-10-28 18:50:09,814 - Train Epoch: 2 [1400/3014 (46%)]	Loss: 0.017725
2020-10-28 18:50:22,717 - Train Epoch: 2 [1600/3014 (53%)]	Loss: 0.037957
2020-10-28 18:50:35,616 - Train Epoch: 2 [1800/3014 (60%)]	Loss: 0.105316
2020-10-28 18:50:48,517 - Train Epoch: 2 [2000/3014 (66%)]	Loss: 0.360285
2020-10-28 18:51:01,419 - Train Epoch: 2 [2200/3014 (73%)]	Loss: 0.082646
2020-10-28 18:51:14,330 - Train Epoch: 2 [2400/3014 (80%)]	Loss: 0.100360
2020-10-28 18:51:27,233 - Train Epoch: 2 [2600/3014 (86%)]	Loss: 0.021545
2020-10-28 18:51:40,141 - Train Epoch: 2 [2800/3014 (93%)]	Loss: 0.042485
2020-10-28 18:51:53,049 - Train Epoch: 2 [3000/3014 (99%)]	Loss: 1.129805
2020-10-28 18:51:53,734 - Starting Validation
2020-10-28 18:52:10,440 - ===> Validation set: Average loss: 0.2743	EER: 9.5826

2020-10-28 18:52:10,468 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank2-tucker-model_best.pth

2020-10-28 18:52:10,468 - #### End epoch 2/30, elapsed time: 211.1724902249407
2020-10-28 18:52:10,727 - Train Epoch: 3 [0/3014 (0%)]	Loss: 0.105311
2020-10-28 18:52:23,643 - Train Epoch: 3 [200/3014 (7%)]	Loss: 0.162814
2020-10-28 18:52:36,559 - Train Epoch: 3 [400/3014 (13%)]	Loss: 0.038614
2020-10-28 18:52:49,475 - Train Epoch: 3 [600/3014 (20%)]	Loss: 0.082204
2020-10-28 18:53:02,387 - Train Epoch: 3 [800/3014 (27%)]	Loss: 0.243834
2020-10-28 18:53:15,298 - Train Epoch: 3 [1000/3014 (33%)]	Loss: 1.253897
2020-10-28 18:53:28,208 - Train Epoch: 3 [1200/3014 (40%)]	Loss: 0.008197
2020-10-28 18:53:41,115 - Train Epoch: 3 [1400/3014 (46%)]	Loss: 0.008922
2020-10-28 18:53:54,020 - Train Epoch: 3 [1600/3014 (53%)]	Loss: 0.056365
2020-10-28 18:54:06,929 - Train Epoch: 3 [1800/3014 (60%)]	Loss: 0.048985
2020-10-28 18:54:19,832 - Train Epoch: 3 [2000/3014 (66%)]	Loss: 0.036821
2020-10-28 18:54:32,733 - Train Epoch: 3 [2200/3014 (73%)]	Loss: 0.028482
2020-10-28 18:54:45,634 - Train Epoch: 3 [2400/3014 (80%)]	Loss: 0.605731
2020-10-28 18:54:58,530 - Train Epoch: 3 [2600/3014 (86%)]	Loss: 0.025386
2020-10-28 18:55:11,432 - Train Epoch: 3 [2800/3014 (93%)]	Loss: 0.081792
2020-10-28 18:55:24,328 - Train Epoch: 3 [3000/3014 (99%)]	Loss: 0.134376
2020-10-28 18:55:25,013 - Starting Validation
2020-10-28 18:55:41,718 - ===> Validation set: Average loss: 0.2736	EER: 9.8684

2020-10-28 18:55:41,720 - #### End epoch 3/30, elapsed time: 211.25216089608148
2020-10-28 18:55:41,979 - Train Epoch: 4 [0/3014 (0%)]	Loss: 0.053311
2020-10-28 18:55:54,886 - Train Epoch: 4 [200/3014 (7%)]	Loss: 0.018020
2020-10-28 18:56:07,790 - Train Epoch: 4 [400/3014 (13%)]	Loss: 0.040369
2020-10-28 18:56:20,695 - Train Epoch: 4 [600/3014 (20%)]	Loss: 0.927483
2020-10-28 18:56:33,592 - Train Epoch: 4 [800/3014 (27%)]	Loss: 0.059724
2020-10-28 18:56:46,490 - Train Epoch: 4 [1000/3014 (33%)]	Loss: 0.610893
2020-10-28 18:56:59,388 - Train Epoch: 4 [1200/3014 (40%)]	Loss: 0.028339
2020-10-28 18:57:12,295 - Train Epoch: 4 [1400/3014 (46%)]	Loss: 0.576229
2020-10-28 18:57:25,193 - Train Epoch: 4 [1600/3014 (53%)]	Loss: 0.056666
2020-10-28 18:57:38,090 - Train Epoch: 4 [1800/3014 (60%)]	Loss: 0.052000
2020-10-28 18:57:50,993 - Train Epoch: 4 [2000/3014 (66%)]	Loss: 0.047046
2020-10-28 18:58:03,893 - Train Epoch: 4 [2200/3014 (73%)]	Loss: 0.184055
2020-10-28 18:58:16,794 - Train Epoch: 4 [2400/3014 (80%)]	Loss: 0.738867
2020-10-28 18:58:29,690 - Train Epoch: 4 [2600/3014 (86%)]	Loss: 0.007342
2020-10-28 18:58:42,586 - Train Epoch: 4 [2800/3014 (93%)]	Loss: 0.024869
2020-10-28 18:58:55,484 - Train Epoch: 4 [3000/3014 (99%)]	Loss: 0.023251
2020-10-28 18:58:56,168 - Starting Validation
2020-10-28 18:59:12,866 - ===> Validation set: Average loss: 0.3056	EER: 10.0000

2020-10-28 18:59:12,868 - #### End epoch 4/30, elapsed time: 211.14718502294272
2020-10-28 18:59:13,126 - Train Epoch: 5 [0/3014 (0%)]	Loss: 0.129871
2020-10-28 18:59:26,034 - Train Epoch: 5 [200/3014 (7%)]	Loss: 0.005621
2020-10-28 18:59:38,938 - Train Epoch: 5 [400/3014 (13%)]	Loss: 0.162306
2020-10-28 18:59:51,839 - Train Epoch: 5 [600/3014 (20%)]	Loss: 0.019470
2020-10-28 19:00:04,746 - Train Epoch: 5 [800/3014 (27%)]	Loss: 0.021895
2020-10-28 19:00:17,648 - Train Epoch: 5 [1000/3014 (33%)]	Loss: 0.549607
2020-10-28 19:00:30,551 - Train Epoch: 5 [1200/3014 (40%)]	Loss: 0.018535
2020-10-28 19:00:43,446 - Train Epoch: 5 [1400/3014 (46%)]	Loss: 0.424011
2020-10-28 19:00:56,345 - Train Epoch: 5 [1600/3014 (53%)]	Loss: 0.562078
2020-10-28 19:01:09,245 - Train Epoch: 5 [1800/3014 (60%)]	Loss: 0.097479
2020-10-28 19:01:22,145 - Train Epoch: 5 [2000/3014 (66%)]	Loss: 0.018323
2020-10-28 19:01:35,042 - Train Epoch: 5 [2200/3014 (73%)]	Loss: 0.055104
2020-10-28 19:01:47,940 - Train Epoch: 5 [2400/3014 (80%)]	Loss: 0.041691
2020-10-28 19:02:00,847 - Train Epoch: 5 [2600/3014 (86%)]	Loss: 0.026328
2020-10-28 19:02:13,743 - Train Epoch: 5 [2800/3014 (93%)]	Loss: 0.025137
2020-10-28 19:02:26,638 - Train Epoch: 5 [3000/3014 (99%)]	Loss: 0.022050
2020-10-28 19:02:27,325 - Starting Validation
2020-10-28 19:02:44,037 - ===> Validation set: Average loss: 0.2656	EER: 8.7368

2020-10-28 19:02:44,065 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank2-tucker-model_best.pth

2020-10-28 19:02:44,065 - #### End epoch 5/30, elapsed time: 211.1970052078832
2020-10-28 19:02:44,324 - Train Epoch: 6 [0/3014 (0%)]	Loss: 0.006718
2020-10-28 19:02:57,221 - Train Epoch: 6 [200/3014 (7%)]	Loss: 0.075418
2020-10-28 19:03:10,127 - Train Epoch: 6 [400/3014 (13%)]	Loss: 0.717928
2020-10-28 19:03:23,020 - Train Epoch: 6 [600/3014 (20%)]	Loss: 0.036784
2020-10-28 19:03:35,914 - Train Epoch: 6 [800/3014 (27%)]	Loss: 0.009776
2020-10-28 19:03:48,809 - Train Epoch: 6 [1000/3014 (33%)]	Loss: 0.425171
2020-10-28 19:04:01,709 - Train Epoch: 6 [1200/3014 (40%)]	Loss: 0.197920
2020-10-28 19:04:14,611 - Train Epoch: 6 [1400/3014 (46%)]	Loss: 0.017673
2020-10-28 19:04:27,511 - Train Epoch: 6 [1600/3014 (53%)]	Loss: 0.017959
2020-10-28 19:04:40,406 - Train Epoch: 6 [1800/3014 (60%)]	Loss: 0.272485
2020-10-28 19:04:53,302 - Train Epoch: 6 [2000/3014 (66%)]	Loss: 0.011213
2020-10-28 19:05:06,203 - Train Epoch: 6 [2200/3014 (73%)]	Loss: 0.032561
2020-10-28 19:05:19,104 - Train Epoch: 6 [2400/3014 (80%)]	Loss: 0.051756
2020-10-28 19:05:32,000 - Train Epoch: 6 [2600/3014 (86%)]	Loss: 0.018270
2020-10-28 19:05:44,899 - Train Epoch: 6 [2800/3014 (93%)]	Loss: 0.047975
2020-10-28 19:05:57,803 - Train Epoch: 6 [3000/3014 (99%)]	Loss: 0.719973
2020-10-28 19:05:58,488 - Starting Validation
2020-10-28 19:06:15,192 - ===> Validation set: Average loss: 0.3040	EER: 10.6579

2020-10-28 19:06:15,194 - #### End epoch 6/30, elapsed time: 211.12893417896703
2020-10-28 19:06:15,453 - Train Epoch: 7 [0/3014 (0%)]	Loss: 0.003338
2020-10-28 19:06:28,355 - Train Epoch: 7 [200/3014 (7%)]	Loss: 0.051137
2020-10-28 19:06:41,259 - Train Epoch: 7 [400/3014 (13%)]	Loss: 0.103926
2020-10-28 19:06:54,163 - Train Epoch: 7 [600/3014 (20%)]	Loss: 0.093844
2020-10-28 19:07:07,065 - Train Epoch: 7 [800/3014 (27%)]	Loss: 0.019193
2020-10-28 19:07:19,974 - Train Epoch: 7 [1000/3014 (33%)]	Loss: 0.051032
2020-10-28 19:07:32,874 - Train Epoch: 7 [1200/3014 (40%)]	Loss: 0.022997
2020-10-28 19:07:45,772 - Train Epoch: 7 [1400/3014 (46%)]	Loss: 0.172497
2020-10-28 19:07:58,666 - Train Epoch: 7 [1600/3014 (53%)]	Loss: 0.230804
2020-10-28 19:08:11,567 - Train Epoch: 7 [1800/3014 (60%)]	Loss: 0.044752
2020-10-28 19:08:24,461 - Train Epoch: 7 [2000/3014 (66%)]	Loss: 0.968836
2020-10-28 19:08:37,356 - Train Epoch: 7 [2200/3014 (73%)]	Loss: 0.058077
2020-10-28 19:08:50,252 - Train Epoch: 7 [2400/3014 (80%)]	Loss: 0.252674
2020-10-28 19:09:03,150 - Train Epoch: 7 [2600/3014 (86%)]	Loss: 0.013752
2020-10-28 19:09:16,055 - Train Epoch: 7 [2800/3014 (93%)]	Loss: 0.692299
2020-10-28 19:09:28,952 - Train Epoch: 7 [3000/3014 (99%)]	Loss: 0.028124
2020-10-28 19:09:29,637 - Starting Validation
2020-10-28 19:09:46,328 - ===> Validation set: Average loss: 0.2918	EER: 10.2632

2020-10-28 19:09:46,330 - #### End epoch 7/30, elapsed time: 211.13614175911061
2020-10-28 19:09:46,589 - Train Epoch: 8 [0/3014 (0%)]	Loss: 0.027233
2020-10-28 19:09:59,494 - Train Epoch: 8 [200/3014 (7%)]	Loss: 0.045119
2020-10-28 19:10:12,396 - Train Epoch: 8 [400/3014 (13%)]	Loss: 0.354336
2020-10-28 19:10:25,299 - Train Epoch: 8 [600/3014 (20%)]	Loss: 0.336798
2020-10-28 19:10:38,198 - Train Epoch: 8 [800/3014 (27%)]	Loss: 0.022113
2020-10-28 19:10:51,098 - Train Epoch: 8 [1000/3014 (33%)]	Loss: 0.202357
2020-10-28 19:11:03,998 - Train Epoch: 8 [1200/3014 (40%)]	Loss: 0.066484
2020-10-28 19:11:16,897 - Train Epoch: 8 [1400/3014 (46%)]	Loss: 0.051888
2020-10-28 19:11:29,792 - Train Epoch: 8 [1600/3014 (53%)]	Loss: 0.155400
2020-10-28 19:11:42,690 - Train Epoch: 8 [1800/3014 (60%)]	Loss: 0.387051
2020-10-28 19:11:55,589 - Train Epoch: 8 [2000/3014 (66%)]	Loss: 0.039319
2020-10-28 19:12:08,500 - Train Epoch: 8 [2200/3014 (73%)]	Loss: 0.785722
2020-10-28 19:12:21,397 - Train Epoch: 8 [2400/3014 (80%)]	Loss: 0.153562
2020-10-28 19:12:34,300 - Train Epoch: 8 [2600/3014 (86%)]	Loss: 0.007351
2020-10-28 19:12:47,199 - Train Epoch: 8 [2800/3014 (93%)]	Loss: 0.219783
2020-10-28 19:13:00,098 - Train Epoch: 8 [3000/3014 (99%)]	Loss: 0.004085
2020-10-28 19:13:00,784 - Starting Validation
2020-10-28 19:13:17,482 - ===> Validation set: Average loss: 0.3164	EER: 10.0000

2020-10-28 19:13:17,484 - #### End epoch 8/30, elapsed time: 211.1540566550102
2020-10-28 19:13:17,743 - Train Epoch: 9 [0/3014 (0%)]	Loss: 0.029992
2020-10-28 19:13:30,647 - Train Epoch: 9 [200/3014 (7%)]	Loss: 0.003386
2020-10-28 19:13:43,544 - Train Epoch: 9 [400/3014 (13%)]	Loss: 0.016374
2020-10-28 19:13:56,452 - Train Epoch: 9 [600/3014 (20%)]	Loss: 0.139796
2020-10-28 19:14:09,355 - Train Epoch: 9 [800/3014 (27%)]	Loss: 0.006252
2020-10-28 19:14:22,259 - Train Epoch: 9 [1000/3014 (33%)]	Loss: 0.026690
2020-10-28 19:14:35,157 - Train Epoch: 9 [1200/3014 (40%)]	Loss: 0.014499
2020-10-28 19:14:48,058 - Train Epoch: 9 [1400/3014 (46%)]	Loss: 0.004992
2020-10-28 19:15:00,954 - Train Epoch: 9 [1600/3014 (53%)]	Loss: 0.042325
2020-10-28 19:15:13,863 - Train Epoch: 9 [1800/3014 (60%)]	Loss: 0.004045
2020-10-28 19:15:26,760 - Train Epoch: 9 [2000/3014 (66%)]	Loss: 0.012423
2020-10-28 19:15:39,658 - Train Epoch: 9 [2200/3014 (73%)]	Loss: 0.018656
2020-10-28 19:15:52,554 - Train Epoch: 9 [2400/3014 (80%)]	Loss: 0.004077
2020-10-28 19:16:05,451 - Train Epoch: 9 [2600/3014 (86%)]	Loss: 0.045614
2020-10-28 19:16:18,347 - Train Epoch: 9 [2800/3014 (93%)]	Loss: 0.005103
2020-10-28 19:16:31,245 - Train Epoch: 9 [3000/3014 (99%)]	Loss: 0.743011
2020-10-28 19:16:31,929 - Starting Validation
2020-10-28 19:16:48,627 - ===> Validation set: Average loss: 0.3213	EER: 9.4737

2020-10-28 19:16:48,629 - #### End epoch 9/30, elapsed time: 211.14471600507386
2020-10-28 19:16:48,888 - Train Epoch: 10 [0/3014 (0%)]	Loss: 0.002844
2020-10-28 19:17:01,789 - Train Epoch: 10 [200/3014 (7%)]	Loss: 0.006883
2020-10-28 19:17:14,698 - Train Epoch: 10 [400/3014 (13%)]	Loss: 0.013975
2020-10-28 19:17:27,598 - Train Epoch: 10 [600/3014 (20%)]	Loss: 0.045830
2020-10-28 19:17:40,498 - Train Epoch: 10 [800/3014 (27%)]	Loss: 0.700155
2020-10-28 19:17:53,404 - Train Epoch: 10 [1000/3014 (33%)]	Loss: 0.014046
2020-10-28 19:18:06,307 - Train Epoch: 10 [1200/3014 (40%)]	Loss: 0.164335
2020-10-28 19:18:19,201 - Train Epoch: 10 [1400/3014 (46%)]	Loss: 0.065168
2020-10-28 19:18:32,093 - Train Epoch: 10 [1600/3014 (53%)]	Loss: 0.007936
2020-10-28 19:18:44,991 - Train Epoch: 10 [1800/3014 (60%)]	Loss: 0.012777
2020-10-28 19:18:57,895 - Train Epoch: 10 [2000/3014 (66%)]	Loss: 0.004282
2020-10-28 19:19:10,800 - Train Epoch: 10 [2200/3014 (73%)]	Loss: 0.016172
2020-10-28 19:19:23,701 - Train Epoch: 10 [2400/3014 (80%)]	Loss: 0.004635
2020-10-28 19:19:36,602 - Train Epoch: 10 [2600/3014 (86%)]	Loss: 0.002787
2020-10-28 19:19:49,504 - Train Epoch: 10 [2800/3014 (93%)]	Loss: 0.016937
2020-10-28 19:20:02,410 - Train Epoch: 10 [3000/3014 (99%)]	Loss: 0.005080
2020-10-28 19:20:03,096 - Starting Validation
2020-10-28 19:20:19,796 - ===> Validation set: Average loss: 0.2849	EER: 9.6842

2020-10-28 19:20:19,799 - #### End epoch 10/30, elapsed time: 211.1696686039213
2020-10-28 19:20:19,799 - #### Avg. training+validation time per epoch: 211.04942930520048
2020-10-28 19:20:19,799 - ################## Done fine-tuning decomp model ######################
2020-10-28 19:20:19,799 - Total elapsed time: 2112.524454799015
