2020-10-28 20:32:25,738 - orignal model size (MB): 0.828236
2020-10-28 20:32:25,739 - # non-zero params before decomp: 185762
2020-10-28 20:32:26,064 - apply [tucker] DECOMP with rank: 4
2020-10-28 20:32:26,070 - decomp-ed model size (MB): 0.179302
2020-10-28 20:32:26,071 - # non-zero params after decomp: 16670
2020-10-28 20:32:26,076 - ===> loading train and dev dataset
2020-10-28 20:32:26,080 - ### Model summary below###
 AttenResNet4(
  (pre): Sequential(
    (0): Sequential(
      (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
  (down1): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att1): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(4, 8), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip1): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down2): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att2): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(8, 16), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip2): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down3): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att3): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(16, 32), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip3): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down4): MaxPool2d(kernel_size=3, stride=(1, 1), padding=0, dilation=1, ceil_mode=False)
  (att4): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(32, 64), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (skip4): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (down5): MaxPool2d(kernel_size=3, stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (att5): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(64, 128), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
  (up5): UpsamplingBilinear2d(size=(137, 851), mode=bilinear)
  (att6): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up4): UpsamplingBilinear2d(size=(201, 979), mode=bilinear)
  (att7): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up3): UpsamplingBilinear2d(size=(233, 1043), mode=bilinear)
  (att8): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up2): UpsamplingBilinear2d(size=(249, 1075), mode=bilinear)
  (att9): Sequential(
    (0): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (up1): UpsamplingBilinear2d(size=(257, 1091), mode=bilinear)
  (conv1): Sequential(
    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): Sequential(
      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): ReLU(inplace=True)
    (5): Sequential(
      (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (soft): Sigmoid()
  (cnn1): Sequential(
    (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re1): ReLU(inplace=True)
  (cnn2): Sequential(
    (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re2): ReLU(inplace=True)
  (cnn3): Sequential(
    (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp1): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn4): Sequential(
    (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re3): ReLU(inplace=True)
  (cnn5): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re4): ReLU(inplace=True)
  (cnn6): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn7): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re5): ReLU(inplace=True)
  (cnn8): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re6): ReLU(inplace=True)
  (cnn9): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn10): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re12): ReLU(inplace=True)
  (cnn11): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re13): ReLU(inplace=True)
  (cnn12): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn13): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re14): ReLU(inplace=True)
  (cnn14): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re15): ReLU(inplace=True)
  (cnn15): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (mp5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (cnn16): Sequential(
    (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)
    (2): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (ln1): Sequential(
    (0): Linear(in_features=768, out_features=4, bias=False)
    (1): Linear(in_features=4, out_features=32, bias=True)
  )
  (bn7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re7): ReLU(inplace=True)
  (ln2): Sequential(
    (0): Linear(in_features=32, out_features=4, bias=False)
    (1): Linear(in_features=4, out_features=32, bias=True)
  )
  (bn8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re8): ReLU(inplace=True)
  (ln3): Sequential(
    (0): Linear(in_features=32, out_features=4, bias=False)
    (1): Linear(in_features=4, out_features=32, bias=True)
  )
  (bn9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re9): ReLU(inplace=True)
  (ln4): Sequential(
    (0): Linear(in_features=32, out_features=4, bias=False)
    (1): Linear(in_features=4, out_features=32, bias=True)
  )
  (bn10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re10): ReLU(inplace=True)
  (ln5): Sequential(
    (0): Linear(in_features=32, out_features=4, bias=False)
    (1): Linear(in_features=4, out_features=32, bias=True)
  )
  (bn11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (re11): ReLU(inplace=True)
  (ln6): Sequential(
    (0): Linear(in_features=32, out_features=1, bias=False)
    (1): Linear(in_features=1, out_features=1, bias=True)
  )
  (sigmoid): Sigmoid()
)

2020-10-28 20:32:26,081 - ===> Model total parameter: 16670

2020-10-28 20:32:26,613 - Train Epoch: 1 [0/3014 (0%)]	Loss: 0.630860
2020-10-28 20:32:41,917 - Train Epoch: 1 [200/3014 (7%)]	Loss: 0.436036
2020-10-28 20:32:57,229 - Train Epoch: 1 [400/3014 (13%)]	Loss: 1.129821
2020-10-28 20:33:12,547 - Train Epoch: 1 [600/3014 (20%)]	Loss: 0.227911
2020-10-28 20:33:27,874 - Train Epoch: 1 [800/3014 (27%)]	Loss: 0.076512
2020-10-28 20:33:43,209 - Train Epoch: 1 [1000/3014 (33%)]	Loss: 0.858416
2020-10-28 20:33:58,545 - Train Epoch: 1 [1200/3014 (40%)]	Loss: 0.021975
2020-10-28 20:34:13,882 - Train Epoch: 1 [1400/3014 (46%)]	Loss: 0.481073
2020-10-28 20:34:29,216 - Train Epoch: 1 [1600/3014 (53%)]	Loss: 0.017875
2020-10-28 20:34:44,546 - Train Epoch: 1 [1800/3014 (60%)]	Loss: 0.107802
2020-10-28 20:34:59,882 - Train Epoch: 1 [2000/3014 (66%)]	Loss: 0.098045
2020-10-28 20:35:15,225 - Train Epoch: 1 [2200/3014 (73%)]	Loss: 1.441941
2020-10-28 20:35:30,562 - Train Epoch: 1 [2400/3014 (80%)]	Loss: 0.712383
2020-10-28 20:35:45,902 - Train Epoch: 1 [2600/3014 (86%)]	Loss: 0.687845
2020-10-28 20:36:01,238 - Train Epoch: 1 [2800/3014 (93%)]	Loss: 0.073582
2020-10-28 20:36:16,576 - Train Epoch: 1 [3000/3014 (99%)]	Loss: 0.221891
2020-10-28 20:36:17,383 - Starting Validation
2020-10-28 20:36:35,292 - ===> Validation set: Average loss: 0.3316	EER: 11.0526

2020-10-28 20:36:35,320 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank4-tucker-model_best.pth

2020-10-28 20:36:35,320 - #### End epoch 1/30, elapsed time: 249.23941557807848
2020-10-28 20:36:35,628 - Train Epoch: 2 [0/3014 (0%)]	Loss: 0.336912
2020-10-28 20:36:50,969 - Train Epoch: 2 [200/3014 (7%)]	Loss: 0.058563
2020-10-28 20:37:06,311 - Train Epoch: 2 [400/3014 (13%)]	Loss: 0.135262
2020-10-28 20:37:21,642 - Train Epoch: 2 [600/3014 (20%)]	Loss: 0.260005
2020-10-28 20:37:36,977 - Train Epoch: 2 [800/3014 (27%)]	Loss: 0.206581
2020-10-28 20:37:52,316 - Train Epoch: 2 [1000/3014 (33%)]	Loss: 0.090099
2020-10-28 20:38:07,645 - Train Epoch: 2 [1200/3014 (40%)]	Loss: 0.476445
2020-10-28 20:38:22,985 - Train Epoch: 2 [1400/3014 (46%)]	Loss: 0.031458
2020-10-28 20:38:38,319 - Train Epoch: 2 [1600/3014 (53%)]	Loss: 0.577570
2020-10-28 20:38:53,647 - Train Epoch: 2 [1800/3014 (60%)]	Loss: 0.587482
2020-10-28 20:39:08,984 - Train Epoch: 2 [2000/3014 (66%)]	Loss: 0.164069
2020-10-28 20:39:24,325 - Train Epoch: 2 [2200/3014 (73%)]	Loss: 0.060769
2020-10-28 20:39:39,665 - Train Epoch: 2 [2400/3014 (80%)]	Loss: 0.084536
2020-10-28 20:39:54,995 - Train Epoch: 2 [2600/3014 (86%)]	Loss: 0.068625
2020-10-28 20:40:10,328 - Train Epoch: 2 [2800/3014 (93%)]	Loss: 0.281191
2020-10-28 20:40:25,661 - Train Epoch: 2 [3000/3014 (99%)]	Loss: 0.042929
2020-10-28 20:40:26,468 - Starting Validation
2020-10-28 20:40:44,353 - ===> Validation set: Average loss: 0.2492	EER: 8.8089

2020-10-28 20:40:44,388 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank4-tucker-model_best.pth

2020-10-28 20:40:44,389 - #### End epoch 2/30, elapsed time: 249.0682422008831
2020-10-28 20:40:44,696 - Train Epoch: 3 [0/3014 (0%)]	Loss: 0.067181
2020-10-28 20:41:00,027 - Train Epoch: 3 [200/3014 (7%)]	Loss: 0.027031
2020-10-28 20:41:15,359 - Train Epoch: 3 [400/3014 (13%)]	Loss: 0.005198
2020-10-28 20:41:30,690 - Train Epoch: 3 [600/3014 (20%)]	Loss: 0.060368
2020-10-28 20:41:46,018 - Train Epoch: 3 [800/3014 (27%)]	Loss: 0.838697
2020-10-28 20:42:01,341 - Train Epoch: 3 [1000/3014 (33%)]	Loss: 0.013056
2020-10-28 20:42:16,668 - Train Epoch: 3 [1200/3014 (40%)]	Loss: 0.108396
2020-10-28 20:42:31,999 - Train Epoch: 3 [1400/3014 (46%)]	Loss: 0.018013
2020-10-28 20:42:47,331 - Train Epoch: 3 [1600/3014 (53%)]	Loss: 0.332888
2020-10-28 20:43:02,666 - Train Epoch: 3 [1800/3014 (60%)]	Loss: 0.035069
2020-10-28 20:43:17,999 - Train Epoch: 3 [2000/3014 (66%)]	Loss: 0.048722
2020-10-28 20:43:33,331 - Train Epoch: 3 [2200/3014 (73%)]	Loss: 0.065930
2020-10-28 20:43:48,662 - Train Epoch: 3 [2400/3014 (80%)]	Loss: 0.449371
2020-10-28 20:44:03,997 - Train Epoch: 3 [2600/3014 (86%)]	Loss: 0.015301
2020-10-28 20:44:19,326 - Train Epoch: 3 [2800/3014 (93%)]	Loss: 1.280605
2020-10-28 20:44:34,658 - Train Epoch: 3 [3000/3014 (99%)]	Loss: 0.088529
2020-10-28 20:44:35,465 - Starting Validation
2020-10-28 20:44:53,355 - ===> Validation set: Average loss: 0.3930	EER: 11.3684

2020-10-28 20:44:53,358 - #### End epoch 3/30, elapsed time: 248.9690432709176
2020-10-28 20:44:53,666 - Train Epoch: 4 [0/3014 (0%)]	Loss: 0.070089
2020-10-28 20:45:09,004 - Train Epoch: 4 [200/3014 (7%)]	Loss: 0.642432
2020-10-28 20:45:24,345 - Train Epoch: 4 [400/3014 (13%)]	Loss: 0.075421
2020-10-28 20:45:39,679 - Train Epoch: 4 [600/3014 (20%)]	Loss: 0.010094
2020-10-28 20:45:55,009 - Train Epoch: 4 [800/3014 (27%)]	Loss: 0.028988
2020-10-28 20:46:10,347 - Train Epoch: 4 [1000/3014 (33%)]	Loss: 0.015215
2020-10-28 20:46:25,676 - Train Epoch: 4 [1200/3014 (40%)]	Loss: 0.036267
2020-10-28 20:46:41,012 - Train Epoch: 4 [1400/3014 (46%)]	Loss: 0.013602
2020-10-28 20:46:56,340 - Train Epoch: 4 [1600/3014 (53%)]	Loss: 0.221891
2020-10-28 20:47:11,673 - Train Epoch: 4 [1800/3014 (60%)]	Loss: 0.060103
2020-10-28 20:47:27,007 - Train Epoch: 4 [2000/3014 (66%)]	Loss: 0.021106
2020-10-28 20:47:42,344 - Train Epoch: 4 [2200/3014 (73%)]	Loss: 0.038259
2020-10-28 20:47:57,680 - Train Epoch: 4 [2400/3014 (80%)]	Loss: 0.082118
2020-10-28 20:48:13,017 - Train Epoch: 4 [2600/3014 (86%)]	Loss: 0.011503
2020-10-28 20:48:28,357 - Train Epoch: 4 [2800/3014 (93%)]	Loss: 0.023944
2020-10-28 20:48:43,692 - Train Epoch: 4 [3000/3014 (99%)]	Loss: 0.011191
2020-10-28 20:48:44,499 - Starting Validation
2020-10-28 20:49:02,381 - ===> Validation set: Average loss: 0.2386	EER: 8.1053

2020-10-28 20:49:02,409 - Snapshot saved to snapshots/attention/decomp-2020-10-14_21_53_09-rank4-tucker-model_best.pth

2020-10-28 20:49:02,410 - #### End epoch 4/30, elapsed time: 249.05186340003274
2020-10-28 20:49:02,716 - Train Epoch: 5 [0/3014 (0%)]	Loss: 0.063666
2020-10-28 20:49:18,049 - Train Epoch: 5 [200/3014 (7%)]	Loss: 0.062423
2020-10-28 20:49:33,382 - Train Epoch: 5 [400/3014 (13%)]	Loss: 0.089969
2020-10-28 20:49:48,724 - Train Epoch: 5 [600/3014 (20%)]	Loss: 0.059104
2020-10-28 20:50:04,061 - Train Epoch: 5 [800/3014 (27%)]	Loss: 0.044743
2020-10-28 20:50:19,393 - Train Epoch: 5 [1000/3014 (33%)]	Loss: 0.009570
2020-10-28 20:50:34,713 - Train Epoch: 5 [1200/3014 (40%)]	Loss: 0.172724
2020-10-28 20:50:50,038 - Train Epoch: 5 [1400/3014 (46%)]	Loss: 0.046290
2020-10-28 20:51:05,369 - Train Epoch: 5 [1600/3014 (53%)]	Loss: 0.013958
2020-10-28 20:51:20,708 - Train Epoch: 5 [1800/3014 (60%)]	Loss: 0.062515
2020-10-28 20:51:36,051 - Train Epoch: 5 [2000/3014 (66%)]	Loss: 0.009301
2020-10-28 20:51:51,390 - Train Epoch: 5 [2200/3014 (73%)]	Loss: 0.060271
2020-10-28 20:52:06,724 - Train Epoch: 5 [2400/3014 (80%)]	Loss: 0.038595
2020-10-28 20:52:22,062 - Train Epoch: 5 [2600/3014 (86%)]	Loss: 0.002639
2020-10-28 20:52:37,395 - Train Epoch: 5 [2800/3014 (93%)]	Loss: 0.011663
2020-10-28 20:52:52,729 - Train Epoch: 5 [3000/3014 (99%)]	Loss: 0.085869
2020-10-28 20:52:53,536 - Starting Validation
2020-10-28 20:53:11,421 - ===> Validation set: Average loss: 0.3300	EER: 11.4364

2020-10-28 20:53:11,423 - #### End epoch 5/30, elapsed time: 249.01345322211273
2020-10-28 20:53:11,730 - Train Epoch: 6 [0/3014 (0%)]	Loss: 0.073067
2020-10-28 20:53:27,068 - Train Epoch: 6 [200/3014 (7%)]	Loss: 0.045844
2020-10-28 20:53:42,404 - Train Epoch: 6 [400/3014 (13%)]	Loss: 0.908052
2020-10-28 20:53:57,737 - Train Epoch: 6 [600/3014 (20%)]	Loss: 0.198209
2020-10-28 20:54:13,065 - Train Epoch: 6 [800/3014 (27%)]	Loss: 0.009290
2020-10-28 20:54:28,398 - Train Epoch: 6 [1000/3014 (33%)]	Loss: 0.360882
2020-10-28 20:54:43,725 - Train Epoch: 6 [1200/3014 (40%)]	Loss: 0.014608
2020-10-28 20:54:59,058 - Train Epoch: 6 [1400/3014 (46%)]	Loss: 0.030003
2020-10-28 20:55:14,389 - Train Epoch: 6 [1600/3014 (53%)]	Loss: 0.002840
2020-10-28 20:55:29,715 - Train Epoch: 6 [1800/3014 (60%)]	Loss: 0.014977
2020-10-28 20:55:45,038 - Train Epoch: 6 [2000/3014 (66%)]	Loss: 0.021319
2020-10-28 20:56:00,365 - Train Epoch: 6 [2200/3014 (73%)]	Loss: 0.008621
2020-10-28 20:56:15,693 - Train Epoch: 6 [2400/3014 (80%)]	Loss: 0.027381
2020-10-28 20:56:31,021 - Train Epoch: 6 [2600/3014 (86%)]	Loss: 0.004967
2020-10-28 20:56:46,354 - Train Epoch: 6 [2800/3014 (93%)]	Loss: 0.178027
2020-10-28 20:57:01,689 - Train Epoch: 6 [3000/3014 (99%)]	Loss: 0.016508
2020-10-28 20:57:02,495 - Starting Validation
2020-10-28 20:57:20,386 - ===> Validation set: Average loss: 0.6055	EER: 15.9109

2020-10-28 20:57:20,388 - #### End epoch 6/30, elapsed time: 248.9646760050673
2020-10-28 20:57:20,695 - Train Epoch: 7 [0/3014 (0%)]	Loss: 0.021943
2020-10-28 20:57:36,033 - Train Epoch: 7 [200/3014 (7%)]	Loss: 0.005382
2020-10-28 20:57:51,359 - Train Epoch: 7 [400/3014 (13%)]	Loss: 0.003578
2020-10-28 20:58:06,694 - Train Epoch: 7 [600/3014 (20%)]	Loss: 0.014474
2020-10-28 20:58:22,017 - Train Epoch: 7 [800/3014 (27%)]	Loss: 0.002837
2020-10-28 20:58:37,347 - Train Epoch: 7 [1000/3014 (33%)]	Loss: 0.176824
2020-10-28 20:58:52,677 - Train Epoch: 7 [1200/3014 (40%)]	Loss: 0.730170
2020-10-28 20:59:08,008 - Train Epoch: 7 [1400/3014 (46%)]	Loss: 0.032840
2020-10-28 20:59:23,349 - Train Epoch: 7 [1600/3014 (53%)]	Loss: 0.013969
2020-10-28 20:59:38,691 - Train Epoch: 7 [1800/3014 (60%)]	Loss: 0.051514
2020-10-28 20:59:54,025 - Train Epoch: 7 [2000/3014 (66%)]	Loss: 0.067275
2020-10-28 21:00:09,361 - Train Epoch: 7 [2200/3014 (73%)]	Loss: 0.722551
2020-10-28 21:00:24,694 - Train Epoch: 7 [2400/3014 (80%)]	Loss: 0.017904
2020-10-28 21:00:40,030 - Train Epoch: 7 [2600/3014 (86%)]	Loss: 0.007396
2020-10-28 21:00:55,357 - Train Epoch: 7 [2800/3014 (93%)]	Loss: 0.006567
2020-10-28 21:01:10,686 - Train Epoch: 7 [3000/3014 (99%)]	Loss: 0.027000
2020-10-28 21:01:11,493 - Starting Validation
2020-10-28 21:01:29,381 - ===> Validation set: Average loss: 0.3275	EER: 9.0789

2020-10-28 21:01:29,383 - #### End epoch 7/30, elapsed time: 248.99505407409742
2020-10-28 21:01:29,690 - Train Epoch: 8 [0/3014 (0%)]	Loss: 0.012839
2020-10-28 21:01:45,024 - Train Epoch: 8 [200/3014 (7%)]	Loss: 0.009943
2020-10-28 21:02:00,358 - Train Epoch: 8 [400/3014 (13%)]	Loss: 0.020758
2020-10-28 21:02:15,691 - Train Epoch: 8 [600/3014 (20%)]	Loss: 0.002577
2020-10-28 21:02:31,019 - Train Epoch: 8 [800/3014 (27%)]	Loss: 0.003666
2020-10-28 21:02:46,345 - Train Epoch: 8 [1000/3014 (33%)]	Loss: 0.001705
2020-10-28 21:03:01,678 - Train Epoch: 8 [1200/3014 (40%)]	Loss: 0.015446
2020-10-28 21:03:17,009 - Train Epoch: 8 [1400/3014 (46%)]	Loss: 0.001595
2020-10-28 21:03:32,351 - Train Epoch: 8 [1600/3014 (53%)]	Loss: 0.003561
2020-10-28 21:03:47,686 - Train Epoch: 8 [1800/3014 (60%)]	Loss: 0.022929
2020-10-28 21:04:03,026 - Train Epoch: 8 [2000/3014 (66%)]	Loss: 0.003398
2020-10-28 21:04:18,361 - Train Epoch: 8 [2200/3014 (73%)]	Loss: 1.029799
2020-10-28 21:04:33,692 - Train Epoch: 8 [2400/3014 (80%)]	Loss: 0.038163
2020-10-28 21:04:49,030 - Train Epoch: 8 [2600/3014 (86%)]	Loss: 0.006077
2020-10-28 21:05:04,366 - Train Epoch: 8 [2800/3014 (93%)]	Loss: 0.004464
2020-10-28 21:05:19,707 - Train Epoch: 8 [3000/3014 (99%)]	Loss: 0.015731
2020-10-28 21:05:20,514 - Starting Validation
2020-10-28 21:05:38,398 - ===> Validation set: Average loss: 0.3643	EER: 9.5195

2020-10-28 21:05:38,400 - #### End epoch 8/30, elapsed time: 249.01692956895567
2020-10-28 21:05:38,707 - Train Epoch: 9 [0/3014 (0%)]	Loss: 0.095654
2020-10-28 21:05:54,042 - Train Epoch: 9 [200/3014 (7%)]	Loss: 0.861947
2020-10-28 21:06:09,381 - Train Epoch: 9 [400/3014 (13%)]	Loss: 0.627673
2020-10-28 21:06:24,725 - Train Epoch: 9 [600/3014 (20%)]	Loss: 0.016585
2020-10-28 21:06:40,063 - Train Epoch: 9 [800/3014 (27%)]	Loss: 0.064982
2020-10-28 21:06:55,392 - Train Epoch: 9 [1000/3014 (33%)]	Loss: 0.036575
2020-10-28 21:07:10,729 - Train Epoch: 9 [1200/3014 (40%)]	Loss: 0.005727
2020-10-28 21:07:26,060 - Train Epoch: 9 [1400/3014 (46%)]	Loss: 0.014501
2020-10-28 21:07:41,402 - Train Epoch: 9 [1600/3014 (53%)]	Loss: 0.783978
2020-10-28 21:07:56,739 - Train Epoch: 9 [1800/3014 (60%)]	Loss: 0.060174
2020-10-28 21:08:12,081 - Train Epoch: 9 [2000/3014 (66%)]	Loss: 0.659888
2020-10-28 21:08:27,423 - Train Epoch: 9 [2200/3014 (73%)]	Loss: 0.024247
2020-10-28 21:08:42,757 - Train Epoch: 9 [2400/3014 (80%)]	Loss: 0.038719
2020-10-28 21:08:58,092 - Train Epoch: 9 [2600/3014 (86%)]	Loss: 0.125334
2020-10-28 21:09:13,431 - Train Epoch: 9 [2800/3014 (93%)]	Loss: 0.004161
2020-10-28 21:09:28,774 - Train Epoch: 9 [3000/3014 (99%)]	Loss: 0.037569
2020-10-28 21:09:29,580 - Starting Validation
2020-10-28 21:09:47,475 - ===> Validation set: Average loss: 0.2800	EER: 9.0789

2020-10-28 21:09:47,477 - #### End epoch 9/30, elapsed time: 249.07733558001928
2020-10-28 21:09:47,478 - #### Avg. training+validation time per epoch: 249.04400143335158
2020-10-28 21:09:47,478 - ################## Done fine-tuning decomp model ######################
2020-10-28 21:09:47,478 - Total elapsed time: 2243.455780494958
